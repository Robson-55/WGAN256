# -*- coding: utf-8 -*-
"""painting_256x256.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lcwuSIWF9HUxNsSnbQytVxOz0rZx7mY_

**Load Google Drive**
"""

#from google.colab import drive
#drive.mount('/content/drive')

"""**Import python libraries**"""
import os
from numpy import expand_dims
from numpy import mean
from numpy import ones
from numpy.random import randn
from numpy.random import randint
from keras.preprocessing.image import ImageDataGenerator
from keras import backend
from keras.optimizers import RMSprop
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Reshape
from keras.layers import Flatten
from keras.layers import Conv2D
from keras.layers import Conv2DTranspose
from keras.layers import LeakyReLU
from keras.layers import BatchNormalization
from keras.initializers import RandomNormal
from keras.constraints import Constraint
from matplotlib import pyplot

"""**Gets color images from a folder of images that is in the same directory as the python file**"""

base_url=os.getcwd()
data_url=os.path.join(base_url, 'Ukiyo_e/')
output_url=os.path.join(base_url, 'output/')

from os import listdir
from numpy import asarray
from numpy import vstack
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
from numpy import savez_compressed

"""**load image from directory, resize to 256x256, convert to grey scale, convert to numpy array**
<br/>
Load image from directory

*   Resize all image into 256x256
*   Resize all image into 256x256
*   Keep/convert into RGB color
*   Convert all images into numpy array
"""

def load_images(path, size=(256,256)):
	data_list = list()
	# enumerate filenames in directory, assume all are images
	for filename in listdir(path):
		# load and resize the image
		pixels = load_img(path + filename, target_size=size, color_mode='rgb') #rgb
		# convert to numpy array
		pixels = img_to_array(pixels)
		# store
		data_list.append(pixels)
	return asarray(data_list)

"""**Load images from directory**
<br/>


*   Load Image from directory
*   Shape of the image which has total images, height, width and channel of images
"""

dataA1 = load_images(data_url)
print('Loaded dataA: ', dataA1.shape)

"""**Data Augmentation**
<br/>
Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks.
"""

train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)



"""**Clip model weights to a given hypercube**
<br/>
The DCGAN does not use any gradient clipping, although the WGAN requires gradient clipping for the critic model.

We can implement weight clipping as a Keras constraint.

This is a class that must extend the Constraint class and define an implementation of the __call__() function for applying the operation and the get_config() function for returning any configuration.

We can also define an __init__() function to set the configuration, in this case, the symmetrical size of the bounding box for the weight hypercube, e.g. 0.01.

The ClipConstraint class is defined below.
"""

class ClipConstraint(Constraint):
	# set clip value when initialized
	def __init__(self, clip_value):
		self.clip_value = clip_value

	# clip model weights to hypercube
	def __call__(self, weights):
		return backend.clip(weights, -self.clip_value, self.clip_value)

	# get the config
	def get_config(self):
		return {'clip_value': self.clip_value}

"""**Calculate wasserstein loss**
<br/>
The Wasserstein loss function seeks to increase the gap between the scores for real and generated images.

We can summarize the function as it is described in the paper as follows:

Critic Loss = [average critic score on real images] – [average critic score on fake images]
Generator Loss = -[average critic score on fake images]
Where the average scores are calculated across a mini-batch of samples.

This is precisely how the loss is implemented for graph-based deep learning frameworks such as PyTorch and TensorFlow.

The calculations are straightforward to interpret once we recall that stochastic gradient descent seeks to minimize loss.

In the case of the generator, a larger score from the critic will result in a smaller loss for the generator, encouraging the critic to output larger scores for fake images. For example, an average score of 10 becomes -10, an average score of 50 becomes -50, which is smaller, and so on.
"""

def wasserstein_loss(y_true, y_pred):
	return backend.mean(y_true * y_pred)

"""**Define the standalone critic model**
<br/>
The DCGAN uses the sigmoid activation function in the output layer of the discriminator to predict the likelihood of a given image being real.

In the WGAN, the critic model requires a linear activation to predict the score of “realness” for a given image.

This can be achieved by setting the ‘activation‘ argument to ‘linear‘ in the output layer of the critic model.
"""

def define_critic(in_shape=(256,256,3)):
	# weight initialization
	init = RandomNormal(stddev=0.02)
	# weight constraint
	const = ClipConstraint(0.01)
	# define model
	model = Sequential()
	# downsample to 14x14
	model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))
	model.add(BatchNormalization())
	model.add(LeakyReLU(alpha=0.2))
	# downsample to 7x7
	model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))
	model.add(BatchNormalization())
	model.add(LeakyReLU(alpha=0.2))
	# scoring, linear activation
	model.add(Flatten())
	model.add(Dense(1))
	# compile model
	opt = RMSprop(lr=0.00005)
	model.compile(loss=wasserstein_loss, optimizer=opt)
	return model

"""**Define the standalone generator model**
<br/>
The define_generator() function below defines the generator model but intentionally does not compile it as it is not trained directly, then returns the model. The size of the latent space is parameterized as a function argument.
"""

def define_generator(latent_dim):
	# weight initialization
	init = RandomNormal(stddev=0.02)
	# define model
	model = Sequential()
	# foundation for 8x8 image
	n_nodes = 64 * 8 * 8
	model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))
	model.add(LeakyReLU(alpha=0.2))
	model.add(Reshape((8, 8, 64)))
	# upsample to 16x16
	model.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))
	model.add(BatchNormalization())
	model.add(LeakyReLU(alpha=0.2))
	# upsample to 32x32
	model.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))
	model.add(BatchNormalization())
	model.add(LeakyReLU(alpha=0.2))
  # upsample to 64x64
	model.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))
	model.add(BatchNormalization())
	model.add(LeakyReLU(alpha=0.2)) 
  # upsample to 128x128
	model.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))
	model.add(BatchNormalization())
	model.add(LeakyReLU(alpha=0.2))  
  # upsample to 256x256
	model.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))
	model.add(BatchNormalization())
	model.add(LeakyReLU(alpha=0.2)) 
	# output 256x256x3
	model.add(Conv2D(3, (7,7), activation='tanh', padding='same', kernel_initializer=init))
	return model

"""**Define the combined generator and critic model, for updating the generator**
<br/>
GAN model can be defined that combines both the generator model and the critic model into one larger model.

This larger model will be used to train the model weights in the generator, using the output and error calculated by the critic model. The critic model is trained separately, and as such, the model weights are marked as not trainable in this larger GAN model to ensure that only the weights of the generator model are updated. This change to the trainability of the critic weights only has an effect when training the combined GAN model, not when training the critic standalone.

This larger GAN model takes as input a point in the latent space, uses the generator model to generate an image, which is fed as input to the critic model, then output scored as real or fake. The model is fit using RMSProp with the custom wasserstein_loss() function.

The define_gan() function below implements this, taking the already defined generator and critic models as input.
"""

def define_gan(generator, critic):
	# make weights in the critic not trainable
	critic.trainable = False
	# connect them
	model = Sequential()
	# add generator
	model.add(generator)
	# add the critic
	model.add(critic)
	# compile model
	opt = RMSprop(lr=0.00005)
	model.compile(loss=wasserstein_loss, optimizer=opt)
	return model

"""**Select real samples**
<br/>
We will require one batch (or a half) batch of real images from the dataset each update to the GAN model. A simple way to achieve this is to select a random sample of images from the dataset each time.

The generate_real_samples() function below implements this, taking the prepared dataset as an argument, selecting and returning a random sample of images and their corresponding label for the critic, specifically target=-1 indicating that they are real images.
"""

def generate_real_samples(dataset, n_samples):
	# choose random instances
	ix = randint(0, dataset.shape[0], n_samples)
	# select images
	X = dataset[ix]
	# generate class labels, -1 for 'real'
	y = -ones((n_samples, 1))
	return X, y

"""**Generate points in latent space as input for the generator**
<br/>
we need inputs for the generator model. These are random points from the latent space, specifically Gaussian distributed random variables.

The generate_latent_points() function implements this, taking the size of the latent space as an argument and the number of points required, and returning them as a batch of input samples for the generator model.
"""

def generate_latent_points(latent_dim, n_samples):
	# generate points in the latent space
	x_input = randn(latent_dim * n_samples)
	# reshape into a batch of inputs for the network
	x_input = x_input.reshape(n_samples, latent_dim)
	return x_input

"""**Use the generator to generate n fake examples, with class labels**
<br/>
The generate_fake_samples() function below implements this, taking the generator model and size of the latent space as arguments, then generating points in the latent space and using them as input to the generator model.

The function returns the generated images and their corresponding label for the critic model, specifically target=1 to indicate they are fake or generated.
"""

def generate_fake_samples(generator, latent_dim, n_samples):
	# generate points in latent space
	x_input = generate_latent_points(latent_dim, n_samples)
	# predict outputs
	X = generator.predict(x_input)
	# create class labels with 1.0 for 'fake'
	y = ones((n_samples, 1))
	return X, y

"""**After every 50 epochs, it has to print an image which contains 4x4 image generations (the print is a 1024x1024 image containing 16 images)**

The summarize_performance() function below takes the generator model at a given point during training and uses it to generate 16 images in a 1024x1024 grid, that are then plotted and saved to file.
"""

import matplotlib
from numpy import asarray
from PIL import Image

def summarize_performance(step, g_model, latent_dim, n_samples=100):
	# prepare fake examples
	X, _ = generate_fake_samples(g_model, latent_dim, n_samples)
	# scale from [-1,1] to [0,1]
	# X = (X + 1) / 2.0
	X = (X + 1) / 2.0	
	# plot images
	for i in range(4 * 4):
		# define subplot		
		pyplot.subplot(4, 4, 1 + i)
		# turn off axis
		pyplot.axis('off')		
		# plot raw pixel data		
		pyplot.imshow(X[i, :, :, 0]) 	#, cmap='brg'
	# save plot to file
	figure = pyplot.gcf()
	figure.subplots_adjust(wspace=0, hspace=0)
	figure.set_size_inches(10,10)
	filename1 = output_url+'generated_plot_50epochs_%04d.png' % (step+1)
	pyplot.savefig(filename1, dpi=100,bbox_inches='tight', pad_inches=0)
	# pyplot.show()
	pyplot.close()

"""**After every 100 epochs it has to print an image which contains 8x8 image generations (the print is a 2048x2048 image containing 64 images)**
<br/>
The summarize_performance_100() function below takes the generator model at a given point during training and uses it to generate 64 images in a 2048x2048 grid, that are then plotted and saved to file after every 100epochs. The model is also saved to file at this time, in case we would like to use it later to generate more images.
"""

def summarize_performance_100(step, g_model, latent_dim, n_samples=100):
	# prepare fake examples
	X, _ = generate_fake_samples(g_model, latent_dim, n_samples)
	# scale from [-1,1] to [0,1]
	X = (X + 1) / 2.0
	# plot images
	for i in range(8 * 8):
		# define subplot		
		pyplot.subplot(8, 8, 1 + i)
		# turn off axis
		pyplot.axis('off')
		# plot raw pixel data		
		pyplot.imshow(X[i, :, :, 0], cmap="brg")
	# save plot to file
	figure = pyplot.gcf()  
	figure.set_size_inches(20,20)
	figure.subplots_adjust(wspace=0, hspace=0)
	image_100_epochs = output_url+'generated_plot_100epochs_%04d.png' % (step+1)
	pyplot.savefig(image_100_epochs, dpi=100,bbox_inches='tight', pad_inches=0)
	pyplot.close()
	# save the generator model every 100 epochs
	model_100_epochs = output_url+'model_100epochs_%04d.h5' % (step+1)
	g_model.save(model_100_epochs)
	print('>Saved: %s and %s' % (image_100_epochs, model_100_epochs))

"""**After every 200 epochs it prints a single image generation**
<br/>
The summarize_performance_200() function below takes the generator model at a given point during training and uses it to generate 1 images in a 1000x1000 grid, that are then plotted and saved to file. The model is also saved to file at this time, in case we would like to use it later to generate more images.
"""

def summarize_performance_200(step, g_model, latent_dim, n_samples=100):
	# prepare fake examples
	X, _ = generate_fake_samples(g_model, latent_dim, n_samples)
	# scale from [-1,1] to [0,1]
	X = (X + 1) / 2.0
	# plot images
	for i in range(1 * 1):
		# define subplot		
		pyplot.subplot(1, 1, 1 + i)
		# turn off axis
		pyplot.axis('off')
		# plot raw pixel data		
		pyplot.imshow(X[i, :, :, 0], cmap="brg") #cmap='gray_r'
	# save plot to file
	figure = pyplot.gcf()  
	figure.subplots_adjust(wspace=0, hspace=0)
	figure.set_size_inches(10,10)
	image_200_epochs = output_url+'generated_plot_200epochs_%04d.png' % (step+1)
	pyplot.savefig(image_200_epochs, dpi=100,bbox_inches='tight', pad_inches=0)
	pyplot.close()

"""**Create a line plot of loss for the gan and save to file**
<br/>
In addition to image quality, it is a good idea to keep track of the loss and accuracy of the model over time.

The loss for the critic for real and fake samples can be tracked for each model update, as can the loss for the generator for each update. These can then be used to create line plots of loss at the end of the training run. The plot_history() function below implements this and saves the results to file.
"""

def plot_history(d1_hist, d2_hist, g_hist):
	# plot history
	pyplot.plot(d1_hist, label='crit_real')
	pyplot.plot(d2_hist, label='crit_fake')
	pyplot.plot(g_hist, label='gen')
	pyplot.legend()
	pyplot.savefig(output_url+'plot_line_plot_loss.png')
	pyplot.close()

"""**Train the generator and critic**
<br/>
The model is fit for 5 training epochs, which is arbitrary, as the model begins generating plausible number-7 digits after perhaps the first few epochs. A batch size of 64 samples is used, and each training epoch involves 1166/64, or about 18, batches of real and fake samples and updates to the model. The model is therefore trained for 5 epochs of 64 batches, or 320 iterations.
"""

def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=20, n_batch=16, n_critic=1):
	# calculate the number of batches per training epoch
	bat_per_epo = int(dataset.shape[0] / n_batch) # 1166 / 32 = 36 iteration = 1epochs
	# calculate the number of training iterations
	n_steps = bat_per_epo * n_epochs
	# calculate the size of half a batch of samples
	half_batch = int(n_batch / 2)
	# lists for keeping track of loss
	c1_hist, c2_hist, g_hist = list(), list(), list()
	# manually enumerate epochs
	for i in range(n_steps):
		# update the critic more than the generator
		c1_tmp, c2_tmp = list(), list()
		for _ in range(n_critic):
			# get randomly selected 'real' samples
			X_real, y_real = generate_real_samples(dataset, half_batch)
			# update critic model weights
			c_loss1 = c_model.train_on_batch(X_real, y_real)
			c1_tmp.append(c_loss1)
			# generate 'fake' examples
			X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)
			# update critic model weights
			c_loss2 = c_model.train_on_batch(X_fake, y_fake)
			c2_tmp.append(c_loss2)
		# store critic loss
		c1_hist.append(mean(c1_tmp))
		c2_hist.append(mean(c2_tmp))
		# prepare points in latent space as input for the generator
		X_gan = generate_latent_points(latent_dim, n_batch)
		# create inverted labels for the fake samples
		y_gan = -ones((n_batch, 1))
		# update the generator via the critic's error
		g_loss = gan_model.train_on_batch(X_gan, y_gan)
		g_hist.append(g_loss) 		
		# summarize loss on this batch
		print('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))
		# evaluate the model performance every '50 epoch'
		# print((i+1) * 5)
		if (i+1) % 75 == 0: # 50 epochs
			summarize_performance(i, g_model, latent_dim)
		if (i+1) % 150 == 0: # 100 epochs
				summarize_performance_100(i, g_model, latent_dim)
		if (i+1) % 300 == 0: # 200 epochs
				summarize_performance_200(i, g_model, latent_dim)	  
	# line plots of loss
	plot_history(c1_hist, c2_hist, g_hist)

"""**Load Function**
<br/>


*   Define latent dim
*   call critic function
*   call generator function
*   call dataset function
"""

# size of the latent space
latent_dim = 50
# create the critic
critic = define_critic()
# create the generator
generator = define_generator(latent_dim)
# create the gan
gan_model = define_gan(generator, critic)
# load image data
dataset = dataA1 #load_real_samples()
print(dataset.shape)

"""**Train model**
<br/>
begin the training process
"""

train(generator, critic, gan_model, dataset, latent_dim)

dataset.shape[0]



"""First, the loss of the critic and generator models is reported to the console each iteration of the training loop. Specifically, 
<br/>
1) c1 is the loss of the critic on real examples, <br/>
2) c2 is the loss of the critic in generated samples, <br/>
3) g is the loss of the generator trained via the critic.
"""

